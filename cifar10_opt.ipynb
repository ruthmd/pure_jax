{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4abee46-3f0a-40eb-8f10-7b06fd46a151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
      "Collecting jax[cuda12]\n",
      "  Using cached jax-0.6.0-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting jaxlib<=0.6.0,>=0.6.0 (from jax[cuda12])\n",
      "  Using cached jaxlib-0.6.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
      "Collecting ml_dtypes>=0.5.0 (from jax[cuda12])\n",
      "  Using cached ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Requirement already satisfied: numpy>=1.25 in /opt/conda/lib/python3.11/site-packages (from jax[cuda12]) (1.26.4)\n",
      "Requirement already satisfied: opt_einsum in /opt/conda/lib/python3.11/site-packages (from jax[cuda12]) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.11.1 in /opt/conda/lib/python3.11/site-packages (from jax[cuda12]) (1.14.1)\n",
      "Collecting jax-cuda12-plugin<=0.6.0,>=0.6.0 (from jax-cuda12-plugin[with-cuda]<=0.6.0,>=0.6.0; extra == \"cuda12\"->jax[cuda12])\n",
      "  Using cached jax_cuda12_plugin-0.6.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting jax-cuda12-pjrt==0.6.0 (from jax-cuda12-plugin<=0.6.0,>=0.6.0->jax-cuda12-plugin[with-cuda]<=0.6.0,>=0.6.0; extra == \"cuda12\"->jax[cuda12])\n",
      "  Using cached jax_cuda12_pjrt-0.6.0-py3-none-manylinux2014_x86_64.whl.metadata (492 bytes)\n",
      "Requirement already satisfied: nvidia-cublas-cu12>=12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from jax-cuda12-plugin[with-cuda]<=0.6.0,>=0.6.0; extra == \"cuda12\"->jax[cuda12]) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12>=12.1.105 in /opt/conda/lib/python3.11/site-packages (from jax-cuda12-plugin[with-cuda]<=0.6.0,>=0.6.0; extra == \"cuda12\"->jax[cuda12]) (12.1.105)\n",
      "Collecting nvidia-cuda-nvcc-cu12>=12.6.85 (from jax-cuda12-plugin[with-cuda]<=0.6.0,>=0.6.0; extra == \"cuda12\"->jax[cuda12])\n",
      "  Using cached nvidia_cuda_nvcc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12>=12.1.105 in /opt/conda/lib/python3.11/site-packages (from jax-cuda12-plugin[with-cuda]<=0.6.0,>=0.6.0; extra == \"cuda12\"->jax[cuda12]) (12.1.105)\n",
      "Collecting nvidia-cudnn-cu12<10.0,>=9.8 (from jax-cuda12-plugin[with-cuda]<=0.6.0,>=0.6.0; extra == \"cuda12\"->jax[cuda12])\n",
      "  Using cached nvidia_cudnn_cu12-9.8.0.87-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: nvidia-cufft-cu12>=11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from jax-cuda12-plugin[with-cuda]<=0.6.0,>=0.6.0; extra == \"cuda12\"->jax[cuda12]) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12>=11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from jax-cuda12-plugin[with-cuda]<=0.6.0,>=0.6.0; extra == \"cuda12\"->jax[cuda12]) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12>=12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from jax-cuda12-plugin[with-cuda]<=0.6.0,>=0.6.0; extra == \"cuda12\"->jax[cuda12]) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12>=2.18.1 in /opt/conda/lib/python3.11/site-packages (from jax-cuda12-plugin[with-cuda]<=0.6.0,>=0.6.0; extra == \"cuda12\"->jax[cuda12]) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12>=12.1.105 in /opt/conda/lib/python3.11/site-packages (from jax-cuda12-plugin[with-cuda]<=0.6.0,>=0.6.0; extra == \"cuda12\"->jax[cuda12]) (12.6.68)\n",
      "Using cached jax_cuda12_plugin-0.6.0-cp311-cp311-manylinux2014_x86_64.whl (15.8 MB)\n",
      "Using cached jax_cuda12_pjrt-0.6.0-py3-none-manylinux2014_x86_64.whl (123.4 MB)\n",
      "Using cached jaxlib-0.6.0-cp311-cp311-manylinux2014_x86_64.whl (87.8 MB)\n",
      "Using cached ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "Using cached jax-0.6.0-py3-none-any.whl (2.3 MB)\n",
      "Using cached nvidia_cuda_nvcc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (40.1 MB)\n",
      "Using cached nvidia_cudnn_cu12-9.8.0.87-py3-none-manylinux_2_27_x86_64.whl (698.0 MB)\n",
      "Installing collected packages: jax-cuda12-pjrt, nvidia-cudnn-cu12, nvidia-cuda-nvcc-cu12, ml_dtypes, jax-cuda12-plugin, jaxlib, jax\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n",
      "    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n",
      "  Attempting uninstall: ml_dtypes\n",
      "    Found existing installation: ml-dtypes 0.4.0\n",
      "    Uninstalling ml-dtypes-0.4.0:\n",
      "      Successfully uninstalled ml-dtypes-0.4.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torch 2.4.1 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.8.0.87 which is incompatible.\n",
      "tensorflow 2.17.0 requires ml-dtypes<0.5.0,>=0.3.1, but you have ml-dtypes 0.5.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed jax-0.6.0 jax-cuda12-pjrt-0.6.0 jax-cuda12-plugin-0.6.0 jaxlib-0.6.0 ml_dtypes-0.5.1 nvidia-cuda-nvcc-cu12-12.8.93 nvidia-cudnn-cu12-9.8.0.87\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install \"jax[cuda12]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8e21f31-16fa-4617-a239-b26c1dcd2c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, grad, value_and_grad, lax\n",
    "import jax.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "import tarfile\n",
    "from urllib import request\n",
    "from tqdm import tqdm\n",
    "from jax.tree_util import tree_map\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee1aa4b9-ba45-4c00-907f-0c5656cb7359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Configuration\n",
    "class CNNConfig:\n",
    "    def __init__(self):\n",
    "        self.input_shape = (1, 32, 32, 3)  # (batch_size, height, width, channels) for CIFAR-10\n",
    "        self.conv1_filters = 64\n",
    "        self.conv2_filters = 128\n",
    "        self.conv3_filters = 256\n",
    "        self.kernel_size = 3\n",
    "        self.dense_units = 512\n",
    "        self.output_classes = 10\n",
    "        # Regularization parameters\n",
    "        self.weight_decay = 1e-4\n",
    "        self.dropout_rate = 0.3\n",
    "        self.batch_norm_momentum = 0.9\n",
    "        self.use_batch_norm = True\n",
    "        self.use_dropout = True\n",
    "        self.use_residual = True\n",
    "        self.use_global_pooling = True\n",
    "\n",
    "# Layer implementations\n",
    "def conv2d(x, w, b, stride=1, padding='SAME'):\n",
    "    \"\"\"Convolutional layer implementation\"\"\"\n",
    "    x = jax.lax.conv_general_dilated(\n",
    "        lhs=x,\n",
    "        rhs=w,\n",
    "        window_strides=(stride, stride),\n",
    "        padding=padding,\n",
    "        dimension_numbers=('NHWC', 'OIHW', 'NHWC')\n",
    "    )\n",
    "    return x + b\n",
    "\n",
    "def batch_norm(x, scale, bias, mean, var, is_training, momentum=0.9, epsilon=1e-5):\n",
    "    \"\"\"Batch normalization layer\"\"\"\n",
    "    if is_training:\n",
    "        # Calculate batch statistics\n",
    "        batch_mean = jnp.mean(x, axis=(0, 1, 2), keepdims=True)\n",
    "        batch_var = jnp.var(x, axis=(0, 1, 2), keepdims=True)\n",
    "        \n",
    "        # Update running stats using exponential moving average\n",
    "        new_mean = momentum * mean + (1 - momentum) * batch_mean\n",
    "        new_var = momentum * var + (1 - momentum) * batch_var\n",
    "        \n",
    "        # Normalize using batch statistics\n",
    "        x_normalized = (x - batch_mean) / jnp.sqrt(batch_var + epsilon)\n",
    "        \n",
    "        # Return normalized output and updated statistics\n",
    "        return scale * x_normalized + bias, new_mean, new_var\n",
    "    else:\n",
    "        # Normalize using running statistics for inference\n",
    "        x_normalized = (x - mean) / jnp.sqrt(var + epsilon)\n",
    "        return scale * x_normalized + bias, mean, var\n",
    "\n",
    "def relu(x):\n",
    "    \"\"\"ReLU activation function\"\"\"\n",
    "    return jnp.maximum(x, 0)\n",
    "\n",
    "def max_pool(x, pool_size=2, stride=2, padding='VALID'):\n",
    "    \"\"\"Max pooling layer implementation\"\"\"\n",
    "    return jax.lax.reduce_window(\n",
    "        x,\n",
    "        -jnp.inf,\n",
    "        jax.lax.max,\n",
    "        window_dimensions=(1, pool_size, pool_size, 1),\n",
    "        window_strides=(1, stride, stride, 1),\n",
    "        padding=padding\n",
    "    )\n",
    "\n",
    "def dropout(x, rate, rng):\n",
    "    \"\"\"Dropout regularization\"\"\"\n",
    "    if rate == 0.0:\n",
    "        return x\n",
    "    \n",
    "    keep_prob = 1.0 - rate\n",
    "    mask = random.bernoulli(rng, keep_prob, shape=x.shape)\n",
    "    return x * mask / keep_prob\n",
    "\n",
    "def dense(x, w, b):\n",
    "    \"\"\"Fully connected layer implementation\"\"\"\n",
    "    return jnp.dot(x, w) + b\n",
    "\n",
    "def global_avg_pool(x):\n",
    "    \"\"\"Global average pooling layer\"\"\"\n",
    "    return jnp.mean(x, axis=(1, 2))\n",
    "\n",
    "\n",
    "\n",
    "def residual_block(x, params, bn_stats, is_training, rng, block_idx, config):\n",
    "    \"\"\"Residual block with batch normalization and dropout\"\"\"\n",
    "    # Store input\n",
    "    orig_x = x\n",
    "    input_channels = x.shape[-1]\n",
    "    \n",
    "    # First convolution\n",
    "    x = conv2d(x, params[f'conv{block_idx}a_w'], params[f'conv{block_idx}a_b'])\n",
    "    x, bn_stats[f'bn{block_idx}a_mean'], bn_stats[f'bn{block_idx}a_var'] = batch_norm(\n",
    "        x, params[f'bn{block_idx}a_scale'], params[f'bn{block_idx}a_bias'],\n",
    "        bn_stats[f'bn{block_idx}a_mean'], bn_stats[f'bn{block_idx}a_var'],\n",
    "        is_training, config.batch_norm_momentum\n",
    "    )\n",
    "    x = relu(x)\n",
    "    \n",
    "    # Second convolution\n",
    "    x = conv2d(x, params[f'conv{block_idx}b_w'], params[f'conv{block_idx}b_b'])\n",
    "    x, bn_stats[f'bn{block_idx}b_mean'], bn_stats[f'bn{block_idx}b_var'] = batch_norm(\n",
    "        x, params[f'bn{block_idx}b_scale'], params[f'bn{block_idx}b_bias'],\n",
    "        bn_stats[f'bn{block_idx}b_mean'], bn_stats[f'bn{block_idx}b_var'],\n",
    "        is_training, config.batch_norm_momentum\n",
    "    )\n",
    "    \n",
    "    # Check if projection is needed\n",
    "    if input_channels != x.shape[-1]:\n",
    "        # Always use projection if dimensions don't match\n",
    "        projection_key = f'conv{block_idx}_proj_w'\n",
    "        # Ensure the projection parameters exist\n",
    "        if projection_key in params:\n",
    "            orig_x = conv2d(orig_x, params[projection_key], params[f'conv{block_idx}_proj_b'])\n",
    "            orig_x, bn_stats[f'bn{block_idx}_proj_mean'], bn_stats[f'bn{block_idx}_proj_var'] = batch_norm(\n",
    "                orig_x, params[f'bn{block_idx}_proj_scale'], params[f'bn{block_idx}_proj_bias'],\n",
    "                bn_stats[f'bn{block_idx}_proj_mean'], bn_stats[f'bn{block_idx}_proj_var'],\n",
    "                is_training, config.batch_norm_momentum\n",
    "            )\n",
    "        else:\n",
    "            # If projection parameters don't exist, skip the residual connection\n",
    "            # This is a fallback and shouldn't happen with proper initialization\n",
    "            orig_x = x\n",
    "    \n",
    "    # Add residual connection and apply ReLU\n",
    "    x = x + orig_x\n",
    "    x = relu(x)\n",
    "    \n",
    "    # Apply dropout if training\n",
    "    if is_training and config.use_dropout:\n",
    "        rng, dropout_rng = random.split(rng)\n",
    "        x = dropout(x, rate=config.dropout_rate/2, rng=dropout_rng)  # Less dropout in conv layers\n",
    "    \n",
    "    return x, bn_stats, rng\n",
    "\n",
    "def initialize_improved_cnn_params(rng, config):\n",
    "    \"\"\"Initialize CNN model parameters with He initialization and batch norm params\"\"\"\n",
    "    params = {}\n",
    "    bn_stats = {}  # For tracking running mean and variance\n",
    "    \n",
    "    subkeys = random.split(rng, 15)  # Generate more subkeys for randomness\n",
    "    key_idx = 0\n",
    "    \n",
    "    # --- First Block ---\n",
    "    # First convolution layer (3->64 channels, needs projection)\n",
    "    params['conv1a_w'] = random.normal(subkeys[key_idx], (\n",
    "        config.conv1_filters, config.input_shape[-1], \n",
    "        config.kernel_size, config.kernel_size)\n",
    "    ) * jnp.sqrt(2/(config.kernel_size**2 * config.input_shape[-1]))\n",
    "    params['conv1a_b'] = jnp.zeros((config.conv1_filters,))\n",
    "    key_idx += 1\n",
    "    \n",
    "    # Batch norm for first conv\n",
    "    params['bn1a_scale'] = jnp.ones((config.conv1_filters,))\n",
    "    params['bn1a_bias'] = jnp.zeros((config.conv1_filters,))\n",
    "    bn_stats['bn1a_mean'] = jnp.zeros((1, 1, 1, config.conv1_filters))\n",
    "    bn_stats['bn1a_var'] = jnp.ones((1, 1, 1, config.conv1_filters))\n",
    "    \n",
    "    # Second convolution in block 1\n",
    "    params['conv1b_w'] = random.normal(subkeys[key_idx], (\n",
    "        config.conv1_filters, config.conv1_filters, \n",
    "        config.kernel_size, config.kernel_size)\n",
    "    ) * jnp.sqrt(2/(config.kernel_size**2 * config.conv1_filters))\n",
    "    params['conv1b_b'] = jnp.zeros((config.conv1_filters,))\n",
    "    key_idx += 1\n",
    "    \n",
    "    # Batch norm for second conv\n",
    "    params['bn1b_scale'] = jnp.ones((config.conv1_filters,))\n",
    "    params['bn1b_bias'] = jnp.zeros((config.conv1_filters,))\n",
    "    bn_stats['bn1b_mean'] = jnp.zeros((1, 1, 1, config.conv1_filters))\n",
    "    bn_stats['bn1b_var'] = jnp.ones((1, 1, 1, config.conv1_filters))\n",
    "    \n",
    "    # Projection for first block (3->64 channels)\n",
    "    params['conv1_proj_w'] = random.normal(subkeys[key_idx], (\n",
    "        config.conv1_filters, config.input_shape[-1], 1, 1)\n",
    "    ) * jnp.sqrt(2/(1 * config.input_shape[-1]))\n",
    "    params['conv1_proj_b'] = jnp.zeros((config.conv1_filters,))\n",
    "    key_idx += 1\n",
    "    \n",
    "    # Batch norm for projection\n",
    "    params['bn1_proj_scale'] = jnp.ones((config.conv1_filters,))\n",
    "    params['bn1_proj_bias'] = jnp.zeros((config.conv1_filters,))\n",
    "    bn_stats['bn1_proj_mean'] = jnp.zeros((1, 1, 1, config.conv1_filters))\n",
    "    bn_stats['bn1_proj_var'] = jnp.ones((1, 1, 1, config.conv1_filters))\n",
    "    \n",
    "    # --- Second Block ---\n",
    "    # First convolution (64->128 channels)\n",
    "    params['conv2a_w'] = random.normal(subkeys[key_idx], (\n",
    "        config.conv2_filters, config.conv1_filters, \n",
    "        config.kernel_size, config.kernel_size)\n",
    "    ) * jnp.sqrt(2/(config.kernel_size**2 * config.conv1_filters))\n",
    "    params['conv2a_b'] = jnp.zeros((config.conv2_filters,))\n",
    "    key_idx += 1\n",
    "    \n",
    "    # Batch norm\n",
    "    params['bn2a_scale'] = jnp.ones((config.conv2_filters,))\n",
    "    params['bn2a_bias'] = jnp.zeros((config.conv2_filters,))\n",
    "    bn_stats['bn2a_mean'] = jnp.zeros((1, 1, 1, config.conv2_filters))\n",
    "    bn_stats['bn2a_var'] = jnp.ones((1, 1, 1, config.conv2_filters))\n",
    "    \n",
    "    # Second convolution\n",
    "    params['conv2b_w'] = random.normal(subkeys[key_idx], (\n",
    "        config.conv2_filters, config.conv2_filters, \n",
    "        config.kernel_size, config.kernel_size)\n",
    "    ) * jnp.sqrt(2/(config.kernel_size**2 * config.conv2_filters))\n",
    "    params['conv2b_b'] = jnp.zeros((config.conv2_filters,))\n",
    "    key_idx += 1\n",
    "    \n",
    "    # Batch norm\n",
    "    params['bn2b_scale'] = jnp.ones((config.conv2_filters,))\n",
    "    params['bn2b_bias'] = jnp.zeros((config.conv2_filters,))\n",
    "    bn_stats['bn2b_mean'] = jnp.zeros((1, 1, 1, config.conv2_filters))\n",
    "    bn_stats['bn2b_var'] = jnp.ones((1, 1, 1, config.conv2_filters))\n",
    "    \n",
    "    # Projection for residual connection (64->128)\n",
    "    params['conv2_proj_w'] = random.normal(subkeys[key_idx], (\n",
    "        config.conv2_filters, config.conv1_filters, 1, 1)\n",
    "    ) * jnp.sqrt(2/(1 * config.conv1_filters))\n",
    "    params['conv2_proj_b'] = jnp.zeros((config.conv2_filters,))\n",
    "    key_idx += 1\n",
    "    \n",
    "    # Batch norm for projection\n",
    "    params['bn2_proj_scale'] = jnp.ones((config.conv2_filters,))\n",
    "    params['bn2_proj_bias'] = jnp.zeros((config.conv2_filters,))\n",
    "    bn_stats['bn2_proj_mean'] = jnp.zeros((1, 1, 1, config.conv2_filters))\n",
    "    bn_stats['bn2_proj_var'] = jnp.ones((1, 1, 1, config.conv2_filters))\n",
    "    \n",
    "    # --- Third Block ---\n",
    "    # First convolution (128->256 channels)\n",
    "    params['conv3a_w'] = random.normal(subkeys[key_idx], (\n",
    "        config.conv3_filters, config.conv2_filters, \n",
    "        config.kernel_size, config.kernel_size)\n",
    "    ) * jnp.sqrt(2/(config.kernel_size**2 * config.conv2_filters))\n",
    "    params['conv3a_b'] = jnp.zeros((config.conv3_filters,))\n",
    "    key_idx += 1\n",
    "    \n",
    "    # Batch norm\n",
    "    params['bn3a_scale'] = jnp.ones((config.conv3_filters,))\n",
    "    params['bn3a_bias'] = jnp.zeros((config.conv3_filters,))\n",
    "    bn_stats['bn3a_mean'] = jnp.zeros((1, 1, 1, config.conv3_filters))\n",
    "    bn_stats['bn3a_var'] = jnp.ones((1, 1, 1, config.conv3_filters))\n",
    "    \n",
    "    # Second convolution\n",
    "    params['conv3b_w'] = random.normal(subkeys[key_idx], (\n",
    "        config.conv3_filters, config.conv3_filters, \n",
    "        config.kernel_size, config.kernel_size)\n",
    "    ) * jnp.sqrt(2/(config.kernel_size**2 * config.conv3_filters))\n",
    "    params['conv3b_b'] = jnp.zeros((config.conv3_filters,))\n",
    "    key_idx += 1\n",
    "    \n",
    "    # Batch norm\n",
    "    params['bn3b_scale'] = jnp.ones((config.conv3_filters,))\n",
    "    params['bn3b_bias'] = jnp.zeros((config.conv3_filters,))\n",
    "    bn_stats['bn3b_mean'] = jnp.zeros((1, 1, 1, config.conv3_filters))\n",
    "    bn_stats['bn3b_var'] = jnp.ones((1, 1, 1, config.conv3_filters))\n",
    "    \n",
    "    # Projection for residual connection (128->256)\n",
    "    params['conv3_proj_w'] = random.normal(subkeys[key_idx], (\n",
    "        config.conv3_filters, config.conv2_filters, 1, 1)\n",
    "    ) * jnp.sqrt(2/(1 * config.conv2_filters))\n",
    "    params['conv3_proj_b'] = jnp.zeros((config.conv3_filters,))\n",
    "    key_idx += 1\n",
    "    \n",
    "    # Batch norm for projection\n",
    "    params['bn3_proj_scale'] = jnp.ones((config.conv3_filters,))\n",
    "    params['bn3_proj_bias'] = jnp.zeros((config.conv3_filters,))\n",
    "    bn_stats['bn3_proj_mean'] = jnp.zeros((1, 1, 1, config.conv3_filters))\n",
    "    bn_stats['bn3_proj_var'] = jnp.ones((1, 1, 1, config.conv3_filters))\n",
    "    \n",
    "    # Calculate dense layer input dim based on whether we use global pooling\n",
    "    if config.use_global_pooling:\n",
    "        dense_input_dim = config.conv3_filters\n",
    "    else:\n",
    "        # Each max pool halves the dimensions\n",
    "        h, w = 32, 32\n",
    "        h, w = h // 2, w // 2  # After first block\n",
    "        h, w = h // 2, w // 2  # After second block \n",
    "        h, w = h // 2, w // 2  # After third block\n",
    "        dense_input_dim = h * w * config.conv3_filters\n",
    "    \n",
    "    # Dense layers\n",
    "    params['dense1_w'] = random.normal(subkeys[key_idx], (dense_input_dim, config.dense_units)) * jnp.sqrt(2/dense_input_dim)\n",
    "    params['dense1_b'] = jnp.zeros((config.dense_units,))\n",
    "    key_idx += 1\n",
    "    \n",
    "    params['dense2_w'] = random.normal(subkeys[key_idx], (config.dense_units, config.output_classes)) * jnp.sqrt(2/config.dense_units)\n",
    "    params['dense2_b'] = jnp.zeros((config.output_classes,))\n",
    "    \n",
    "    return params, bn_stats\n",
    "\n",
    "def forward_pass(params, bn_stats, x, is_training, rng, config):\n",
    "    \"\"\"Forward pass through the improved CNN model with regularization techniques\"\"\"\n",
    "    # Residual block 1\n",
    "    x, bn_stats, rng = residual_block(x, params, bn_stats, is_training, rng, 1, config)\n",
    "    x = max_pool(x)\n",
    "    \n",
    "    # Residual block 2\n",
    "    x, bn_stats, rng = residual_block(x, params, bn_stats, is_training, rng, 2, config)\n",
    "    x = max_pool(x)\n",
    "    \n",
    "    # Residual block 3\n",
    "    x, bn_stats, rng = residual_block(x, params, bn_stats, is_training, rng, 3, config)\n",
    "    x = max_pool(x)\n",
    "    \n",
    "    # Feature pooling\n",
    "    if config.use_global_pooling:\n",
    "        x = global_avg_pool(x)\n",
    "    else:\n",
    "        x = x.reshape((x.shape[0], -1))  # Flatten\n",
    "    \n",
    "    # Dense layers\n",
    "    x = dense(x, params['dense1_w'], params['dense1_b'])\n",
    "    x = relu(x)\n",
    "    \n",
    "    # Dropout for fully connected layer\n",
    "    if is_training and config.use_dropout:\n",
    "        rng, dropout_rng = random.split(rng)\n",
    "        x = dropout(x, rate=config.dropout_rate, rng=dropout_rng)\n",
    "    \n",
    "    # Output layer\n",
    "    x = dense(x, params['dense2_w'], params['dense2_b'])\n",
    "    \n",
    "    return x, bn_stats, rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea3a582a-f518-4617-8860-516378f6a194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers with weight decay\n",
    "class AdamWOptimizer:\n",
    "    \"\"\"Adam optimizer with decoupled weight decay (AdamW)\"\"\"\n",
    "    def __init__(self, learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8, weight_decay=1e-4):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.weight_decay = weight_decay\n",
    "    \n",
    "    def init(self, params):\n",
    "        \"\"\"Initialize optimizer state\"\"\"\n",
    "        # Return optimizer state instead of storing it as instance variables\n",
    "        return {\n",
    "            'm': tree_map(jnp.zeros_like, params),\n",
    "            'v': tree_map(jnp.zeros_like, params),\n",
    "            't': 0\n",
    "        }\n",
    "    \n",
    "    def update(self, params, grads, opt_state):\n",
    "        \"\"\"Update parameters using gradients and optimizer state\"\"\"\n",
    "        # Unpack optimizer state\n",
    "        m, v, t = opt_state['m'], opt_state['v'], opt_state['t']\n",
    "        \n",
    "        # Increment timestep\n",
    "        t = t + 1\n",
    "        \n",
    "        # Update biased first moment estimate\n",
    "        m = tree_map(\n",
    "            lambda m_i, g_i: self.beta1 * m_i + (1 - self.beta1) * g_i, \n",
    "            m, grads\n",
    "        )\n",
    "        \n",
    "        # Update biased second raw moment estimate\n",
    "        v = tree_map(\n",
    "            lambda v_i, g_i: self.beta2 * v_i + (1 - self.beta2) * (g_i * g_i), \n",
    "            v, grads\n",
    "        )\n",
    "        \n",
    "        # Compute bias-corrected first moment estimate\n",
    "        m_hat = tree_map(\n",
    "            lambda m_i: m_i / (1 - self.beta1 ** t), \n",
    "            m\n",
    "        )\n",
    "        \n",
    "        # Compute bias-corrected second raw moment estimate\n",
    "        v_hat = tree_map(\n",
    "            lambda v_i: v_i / (1 - self.beta2 ** t), \n",
    "            v\n",
    "        )\n",
    "        \n",
    "        # Update parameters with Adam and weight decay separately\n",
    "        updated_params = tree_map(\n",
    "            lambda p, m_h, v_h: (1 - self.weight_decay * self.learning_rate) * p - \n",
    "                              self.learning_rate * m_h / (jnp.sqrt(v_h) + self.epsilon),\n",
    "            params, m_hat, v_hat\n",
    "        )\n",
    "        \n",
    "        # Return updated parameters and optimizer state\n",
    "        updated_opt_state = {'m': m, 'v': v, 't': t}\n",
    "        return updated_params, updated_opt_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29b43372-aa83-4934-9089-db20e818fae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate schedules\n",
    "def cosine_decay_schedule(initial_lr, epoch, total_epochs, warmup_epochs=5):\n",
    "    \"\"\"Cosine annealing learning rate schedule with warmup\"\"\"\n",
    "    if epoch < warmup_epochs:\n",
    "        # Linear warmup\n",
    "        return initial_lr * (epoch + 1) / warmup_epochs\n",
    "    else:\n",
    "        # Cosine decay\n",
    "        decay_epochs = total_epochs - warmup_epochs\n",
    "        epoch_adj = epoch - warmup_epochs\n",
    "        return initial_lr * 0.5 * (1 + jnp.cos(jnp.pi * epoch_adj / decay_epochs))\n",
    "\n",
    "# Metrics and Loss Function\n",
    "def cross_entropy_loss(params, bn_stats, batch_images, batch_labels, is_training, rng, config):\n",
    "    \"\"\"Compute cross entropy loss with L2 regularization for a batch of images\"\"\"\n",
    "    # Get model predictions\n",
    "    logits, updated_bn_stats, new_rng = forward_pass(params, bn_stats, batch_images, is_training, rng, config)\n",
    "    \n",
    "    # Compute log probabilities\n",
    "    log_probs = nn.log_softmax(logits)\n",
    "    \n",
    "    # Convert labels to one-hot encoding\n",
    "    one_hot = jax.nn.one_hot(batch_labels, config.output_classes)\n",
    "    \n",
    "    # Compute cross entropy loss (negative log likelihood)\n",
    "    ce_loss = -jnp.sum(one_hot * log_probs) / batch_images.shape[0]\n",
    "    \n",
    "    # Note: Weight decay is applied separately in the optimizer, not in the loss\n",
    "    \n",
    "    return ce_loss, updated_bn_stats, new_rng\n",
    "\n",
    "def compute_accuracy(params, bn_stats, batch_images, batch_labels, rng, config):\n",
    "    \"\"\"Compute accuracy for a batch of images\"\"\"\n",
    "    # Get model predictions in inference mode (is_training=False)\n",
    "    logits, _, _ = forward_pass(params, bn_stats, batch_images, False, rng, config)\n",
    "    \n",
    "    # Get predicted class indices\n",
    "    preds = jnp.argmax(logits, axis=-1)\n",
    "    \n",
    "    # Compute accuracy\n",
    "    return jnp.mean(preds == batch_labels)\n",
    "\n",
    "def precision_recall_f1(params, bn_stats, batch_images, batch_labels, rng, config):\n",
    "    \"\"\"Compute precision, recall, and F1 score for a batch of images\"\"\"\n",
    "    # Get model predictions in inference mode\n",
    "    logits, _, _ = forward_pass(params, bn_stats, batch_images, False, rng, config)\n",
    "    preds = jnp.argmax(logits, axis=-1)\n",
    "    \n",
    "    # Number of classes (CIFAR-10 has 10 classes)\n",
    "    num_classes = 10\n",
    "    \n",
    "    # Initialize lists for metrics\n",
    "    precision_list, recall_list, f1_list = [], [], []\n",
    "    \n",
    "    # Compute metrics for each class\n",
    "    for cls in range(num_classes):\n",
    "        # True positives, false positives, false negatives\n",
    "        tp = jnp.sum((preds == cls) & (batch_labels == cls))\n",
    "        fp = jnp.sum((preds == cls) & (batch_labels != cls))\n",
    "        fn = jnp.sum((preds != cls) & (batch_labels == cls))\n",
    "        \n",
    "        # Compute precision, recall, and F1 with small epsilon to avoid division by zero\n",
    "        epsilon = 1e-8\n",
    "        precision = tp / (tp + fp + epsilon)\n",
    "        recall = tp / (tp + fn + epsilon)\n",
    "        f1 = 2 * precision * recall / (precision + recall + epsilon)\n",
    "        \n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_list.append(f1)\n",
    "    \n",
    "    # Return average metrics across all classes\n",
    "    return jnp.mean(jnp.array(precision_list)), jnp.mean(jnp.array(recall_list)), jnp.mean(jnp.array(f1_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd3aa57f-4511-4164-93ec-2581cd73fe14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading with Augmentation\n",
    "def download_cifar10(data_dir):\n",
    "    \"\"\"Download CIFAR-10 dataset if it doesn't exist\"\"\"\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "    \n",
    "    # URLs for CIFAR-10 dataset\n",
    "    base_url = \"https://www.cs.toronto.edu/~kriz/\"\n",
    "    train_file = \"cifar-10-python.tar.gz\"\n",
    "    train_url = base_url + train_file\n",
    "    train_path = os.path.join(data_dir, train_file)\n",
    "    \n",
    "    # Download the dataset if not already present\n",
    "    if not os.path.exists(train_path):\n",
    "        print(f\"Downloading CIFAR-10 dataset from {train_url}...\")\n",
    "        request.urlretrieve(train_url, train_path)\n",
    "        print(\"Download complete.\")\n",
    "    else:\n",
    "        print(\"CIFAR-10 dataset already exists.\")\n",
    "    \n",
    "    return train_path\n",
    "\n",
    "def unpickle(file):\n",
    "    \"\"\"Unpickle CIFAR-10 batch files\"\"\"\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "def load_cifar10_raw(data_dir):\n",
    "    \"\"\"\n",
    "    Load CIFAR-10 dataset from raw files\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (train_images, train_labels, test_images, test_labels)\n",
    "    \"\"\"\n",
    "    # Download dataset if needed\n",
    "    cifar_path = download_cifar10(data_dir)\n",
    "    \n",
    "    # Extract files if not already extracted\n",
    "    cifar_dir = os.path.join(data_dir, \"cifar-10-batches-py\")\n",
    "    if not os.path.exists(cifar_dir):\n",
    "        print(\"Extracting CIFAR-10 files...\")\n",
    "        with tarfile.open(cifar_path, 'r:gz') as tar:\n",
    "            tar.extractall(path=data_dir)\n",
    "        print(\"Extraction complete.\")\n",
    "    \n",
    "    # Load training data (batches 1-5)\n",
    "    train_images = []\n",
    "    train_labels = []\n",
    "    for i in range(1, 6):\n",
    "        batch_file = os.path.join(cifar_dir, f\"data_batch_{i}\")\n",
    "        batch_data = unpickle(batch_file)\n",
    "        train_images.append(batch_data[b'data'])\n",
    "        train_labels.extend(batch_data[b'labels'])\n",
    "    \n",
    "    # Reshape training data\n",
    "    train_images = np.vstack(train_images).reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)\n",
    "    train_labels = np.array(train_labels)\n",
    "    \n",
    "    # Load test data\n",
    "    test_batch_file = os.path.join(cifar_dir, \"test_batch\")\n",
    "    test_data = unpickle(test_batch_file)\n",
    "    test_images = test_data[b'data'].reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)\n",
    "    test_labels = np.array(test_data[b'labels'])\n",
    "    \n",
    "    return train_images, train_labels, test_images, test_labels\n",
    "\n",
    "# Data augmentation functions\n",
    "def random_flip(rng, image):\n",
    "    \"\"\"Randomly flip image horizontally\"\"\"\n",
    "    flip_rng, rng = random.split(rng)\n",
    "    should_flip = random.bernoulli(flip_rng, 0.5)\n",
    "    flipped_image = jnp.fliplr(image)\n",
    "    return jnp.where(should_flip, flipped_image, image), rng\n",
    "\n",
    "def random_crop(rng, image, padding=4):\n",
    "    \"\"\"Randomly crop image with padding\"\"\"\n",
    "    crop_rng, rng = random.split(rng)\n",
    "    \n",
    "    # Pad the image\n",
    "    padded = jnp.pad(image, ((padding, padding), (padding, padding), (0, 0)), mode='constant')\n",
    "    \n",
    "    # Generate random crop coordinates\n",
    "    h_offset = random.randint(crop_rng, shape=(), minval=0, maxval=2*padding)\n",
    "    crop_rng, rng = random.split(rng)\n",
    "    w_offset = random.randint(crop_rng, shape=(), minval=0, maxval=2*padding)\n",
    "    \n",
    "    # Perform crop\n",
    "    cropped = lax.dynamic_slice(padded, (h_offset, w_offset, 0), (32, 32, 3))\n",
    "    \n",
    "    return cropped, rng\n",
    "\n",
    "def random_brightness(rng, image, delta=0.1):\n",
    "    \"\"\"Randomly adjust brightness\"\"\"\n",
    "    bright_rng, rng = random.split(rng)\n",
    "    factor = 1.0 + random.uniform(bright_rng, shape=(), minval=-delta, maxval=delta)\n",
    "    return jnp.clip(image * factor, 0.0, 1.0), rng\n",
    "\n",
    "def cutout(rng, image, size=8):\n",
    "    \"\"\"Apply cutout augmentation\"\"\"\n",
    "    cutout_rng, h_rng, w_rng, rng = random.split(rng, 4)\n",
    "    apply_cutout = random.bernoulli(cutout_rng, 0.5)\n",
    "    \n",
    "    h, w = image.shape[0], image.shape[1]\n",
    "    center_h = random.randint(h_rng, shape=(), minval=0, maxval=h)\n",
    "    center_w = random.randint(w_rng, shape=(), minval=0, maxval=w)\n",
    "    \n",
    "    # Calculate cutout boundaries\n",
    "    lower_h = jnp.maximum(0, center_h - size // 2)\n",
    "    upper_h = jnp.minimum(h, center_h + size // 2)\n",
    "    lower_w = jnp.maximum(0, center_w - size // 2)\n",
    "    upper_w = jnp.minimum(w, center_w + size // 2)\n",
    "    \n",
    "    # Create mask indices\n",
    "    mask_h = jnp.arange(h)[:, jnp.newaxis]\n",
    "    mask_w = jnp.arange(w)\n",
    "    \n",
    "    # Create the mask\n",
    "    mask = ((mask_h >= lower_h) & (mask_h < upper_h) & \n",
    "            (mask_w >= lower_w) & (mask_w < upper_w))\n",
    "    mask = 1.0 - mask[:, :, jnp.newaxis]  # Invert and add channel dimension\n",
    "    \n",
    "    # Apply the mask conditionally\n",
    "    return jnp.where(apply_cutout, image * mask, image), rng\n",
    "\n",
    "def apply_augmentation(rng, image):\n",
    "    \"\"\"Apply a series of augmentations to an image\"\"\"\n",
    "    # Random horizontal flip\n",
    "    image, rng = random_flip(rng, image)\n",
    "    \n",
    "    # Random crop with padding\n",
    "    image, rng = random_crop(rng, image)\n",
    "    \n",
    "    # Random brightness adjustment\n",
    "    image, rng = random_brightness(rng, image)\n",
    "    \n",
    "    # Cutout augmentation\n",
    "    image, rng = cutout(rng, image)\n",
    "    \n",
    "    return image, rng\n",
    "\n",
    "def augment_batch(rng, batch_images):\n",
    "    \"\"\"Apply augmentation to a batch of images\"\"\"\n",
    "    # Create a new rng for each image\n",
    "    rngs = random.split(rng, batch_images.shape[0] + 1)\n",
    "    new_rng = rngs[0]\n",
    "    \n",
    "    # Apply augmentation to each image\n",
    "    augmented_images = []\n",
    "    for i, image in enumerate(batch_images):\n",
    "        aug_image, _ = apply_augmentation(rngs[i+1], image)\n",
    "        augmented_images.append(aug_image)\n",
    "    \n",
    "    return jnp.array(augmented_images), new_rng\n",
    "\n",
    "def create_batches(images, labels, batch_size, shuffle=True):\n",
    "    \"\"\"Create batches of data for training/evaluation\"\"\"\n",
    "    num_examples = len(images)\n",
    "    indices = np.arange(num_examples)\n",
    "    \n",
    "    if shuffle:\n",
    "        np.random.shuffle(indices)\n",
    "    \n",
    "    # Create list of batches\n",
    "    batches = []\n",
    "    for start_idx in range(0, num_examples, batch_size):\n",
    "        end_idx = min(start_idx + batch_size, num_examples)\n",
    "        batch_indices = indices[start_idx:end_idx]\n",
    "        batches.append((images[batch_indices], labels[batch_indices]))\n",
    "    \n",
    "    return batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19d4cc44-ad62-4822-b65c-a65596b914a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar10(batch_size=128, seed=0, valid_ratio=0.1):\n",
    "    \"\"\"\n",
    "    Load and preprocess CIFAR-10 dataset with validation split\n",
    "    \n",
    "    Args:\n",
    "        batch_size: Batch size for training/evaluation\n",
    "        seed: Random seed for shuffling\n",
    "        valid_ratio: Ratio of training data to use for validation\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (train_batches, valid_batches, test_batches)\n",
    "    \"\"\"\n",
    "    # Set random seed for reproducibility\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Check if preprocessed data exists in cache\n",
    "    data_dir = \"cifar10_data\"\n",
    "    cache_file = os.path.join(data_dir, \"cifar10_preprocessed.pkl\")\n",
    "    if os.path.exists(cache_file):\n",
    "        print(\"Loading preprocessed CIFAR-10 data from cache...\")\n",
    "        with open(cache_file, 'rb') as f:\n",
    "            train_images, train_labels, test_images, test_labels = pickle.load(f)\n",
    "    else:\n",
    "        print(\"Loading CIFAR-10 from raw files...\")\n",
    "        # Load raw data\n",
    "        train_images, train_labels, test_images, test_labels = load_cifar10_raw(data_dir)\n",
    "        \n",
    "        # Preprocess images: normalize to [0,1]\n",
    "        train_images = train_images.astype(np.float32) / 255.0\n",
    "        test_images = test_images.astype(np.float32) / 255.0\n",
    "        \n",
    "        # Cache the preprocessed data\n",
    "        os.makedirs(data_dir, exist_ok=True)\n",
    "        with open(cache_file, 'wb') as f:\n",
    "            pickle.dump((train_images, train_labels, test_images, test_labels), f)\n",
    "        print(f\"Saved preprocessed data to {cache_file}\")\n",
    "    \n",
    "    # Create validation split\n",
    "    num_train = len(train_images)\n",
    "    num_valid = int(valid_ratio * num_train)\n",
    "    \n",
    "    # Shuffle before splitting\n",
    "    indices = np.random.permutation(num_train)\n",
    "    valid_indices = indices[:num_valid]\n",
    "    train_indices = indices[num_valid:]\n",
    "    \n",
    "    valid_images, valid_labels = train_images[valid_indices], train_labels[valid_indices]\n",
    "    train_images, train_labels = train_images[train_indices], train_labels[train_indices]\n",
    "    \n",
    "    # Create batches\n",
    "    train_batches = create_batches(train_images, train_labels, batch_size, shuffle=True)\n",
    "    valid_batches = create_batches(valid_images, valid_labels, batch_size, shuffle=False)\n",
    "    test_batches = create_batches(test_images, test_labels, batch_size, shuffle=False)\n",
    "    \n",
    "    print(f\"Created {len(train_batches)} training batches, {len(valid_batches)} validation batches, and {len(test_batches)} test batches\")\n",
    "    return train_batches, valid_batches, test_batches\n",
    "\n",
    "def plot_training_curves(train_losses, valid_losses, train_accuracies, valid_accuracies):\n",
    "    \"\"\"Plot training and validation curves for loss and accuracy\"\"\"\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    # Loss curve\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(valid_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Loss Curve')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Accuracy curve\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accuracies, label='Train Accuracy')\n",
    "    plt.plot(valid_accuracies, label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('Accuracy Curve')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('cifar10_improved_training_curves.png')\n",
    "    plt.show()\n",
    "\n",
    "def select_device(device_type=\"auto\"):\n",
    "    \"\"\"\n",
    "    Select appropriate device for training (CPU/GPU/TPU)\n",
    "    \n",
    "    Args:\n",
    "        device_type: 'cpu', 'gpu', or 'auto' to automatically select\n",
    "        \n",
    "    Returns:\n",
    "        Selected JAX device\n",
    "    \"\"\"\n",
    "    if device_type == \"cpu\":\n",
    "        device = jax.devices(\"cpu\")[0]\n",
    "    elif device_type == \"gpu\":\n",
    "        try:\n",
    "            gpus = jax.devices(\"gpu\")\n",
    "            if not gpus:\n",
    "                raise RuntimeError(\"No GPU found, falling back to CPU\")\n",
    "            device = gpus[0]\n",
    "        except RuntimeError:\n",
    "            print(\"Warning: GPU requested but not available. Using CPU instead.\")\n",
    "            device = jax.devices(\"cpu\")[0]\n",
    "    else:  # Auto mode\n",
    "        # Try to use GPU if available, otherwise use CPU\n",
    "        try:\n",
    "            gpus = jax.devices(\"gpu\")\n",
    "            if gpus:\n",
    "                device = gpus[0]\n",
    "                print(\"GPU detected, using GPU for training\")\n",
    "            else:\n",
    "                device = jax.devices(\"cpu\")[0]\n",
    "                print(\"No GPU detected, using CPU for training\")\n",
    "        except:\n",
    "            device = jax.devices(\"cpu\")[0]\n",
    "            print(\"Error detecting GPUs, falling back to CPU\")\n",
    "    \n",
    "    print(f\"✅ Using device: {device}\")\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3df1f2ed-61f2-498d-9576-11d904615ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Checkpointing\n",
    "def save_model(params, bn_stats, path='best_cifar10_model.pkl'):\n",
    "    \"\"\"Save model parameters and batch norm statistics to a file\"\"\"\n",
    "    os.makedirs(os.path.dirname(path) if os.path.dirname(path) else '.', exist_ok=True)\n",
    "    \n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump((params, bn_stats), f)\n",
    "    print(f\"✅ Model saved at {path}\")\n",
    "\n",
    "def load_model(path='best_cifar10_model.pkl'):\n",
    "    \"\"\"Load model parameters from a file\"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Model file not found: {path}\")\n",
    "    \n",
    "    with open(path, 'rb') as f:\n",
    "        params, bn_stats = pickle.load(f)\n",
    "    print(f\"✅ Model loaded from {path}\")\n",
    "    return params, bn_stats\n",
    "\n",
    "# Evaluation\n",
    "def evaluate(params, bn_stats, data_batches, rng, config):\n",
    "    \"\"\"\n",
    "    Evaluate model on a set of batches\n",
    "    \n",
    "    Args:\n",
    "        params: Model parameters\n",
    "        bn_stats: Batch normalization statistics\n",
    "        data_batches: List of (images, labels) batches\n",
    "        rng: Random key for deterministic evaluation\n",
    "        config: Model configuration\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of evaluation metrics\n",
    "    \"\"\"\n",
    "    # Initialize metrics\n",
    "    losses, accs, precs, recs, f1s = [], [], [], [], []\n",
    "    \n",
    "    # Evaluate on each batch\n",
    "    for batch_images, batch_labels in data_batches:\n",
    "        # Convert to JAX arrays\n",
    "        batch_images = jnp.array(batch_images)\n",
    "        batch_labels = jnp.array(batch_labels)\n",
    "        \n",
    "        # No augmentation for evaluation\n",
    "        # Forward pass in evaluation mode (is_training=False)\n",
    "        logits, _, _ = forward_pass(params, bn_stats, batch_images, False, rng, config)\n",
    "        \n",
    "        # Compute metrics\n",
    "        loss = -jnp.mean(jnp.sum(jax.nn.one_hot(batch_labels, config.output_classes) * \n",
    "                                nn.log_softmax(logits), axis=1))\n",
    "        \n",
    "        preds = jnp.argmax(logits, axis=-1)\n",
    "        acc = jnp.mean(preds == batch_labels)\n",
    "        \n",
    "        precision, recall, f1 = precision_recall_f1(params, bn_stats, batch_images, batch_labels, rng, config)\n",
    "        \n",
    "        # Collect results\n",
    "        losses.append(loss)\n",
    "        accs.append(acc)\n",
    "        precs.append(precision)\n",
    "        recs.append(recall)\n",
    "        f1s.append(f1)\n",
    "    \n",
    "    # Calculate average metrics\n",
    "    return {\n",
    "        'loss': jnp.mean(jnp.array(losses)),\n",
    "        'accuracy': jnp.mean(jnp.array(accs)),\n",
    "        'precision': jnp.mean(jnp.array(precs)),\n",
    "        'recall': jnp.mean(jnp.array(recs)),\n",
    "        'f1': jnp.mean(jnp.array(f1s)),\n",
    "    }\n",
    "\n",
    "# Early Stopping\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stopping to prevent overfitting\"\"\"\n",
    "    def __init__(self, patience=10, min_delta=0.001):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = float('inf')\n",
    "        self.early_stop = False\n",
    "    \n",
    "    def __call__(self, val_loss):\n",
    "        if val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        \n",
    "        return self.early_stop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1105970b-e91c-4f88-b411-0c7994d5846a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(params, bn_stats, batch_images, batch_labels, is_training, rng, config):\n",
    "    \"\"\"Compute cross entropy loss with L2 regularization for a batch of images\"\"\"\n",
    "    # Get model predictions\n",
    "    logits, updated_bn_stats, new_rng = forward_pass(params, bn_stats, batch_images, is_training, rng, config)\n",
    "    \n",
    "    # Compute log probabilities\n",
    "    log_probs = nn.log_softmax(logits)\n",
    "    \n",
    "    # Convert labels to one-hot encoding\n",
    "    one_hot = jax.nn.one_hot(batch_labels, config.output_classes)\n",
    "    \n",
    "    # Compute cross entropy loss (negative log likelihood)\n",
    "    ce_loss = -jnp.sum(one_hot * log_probs) / batch_images.shape[0]\n",
    "    \n",
    "    # Note: Weight decay is applied separately in the optimizer, not in the loss\n",
    "    \n",
    "    return ce_loss, (updated_bn_stats, new_rng)\n",
    "\n",
    "def train_step(params, bn_stats, batch_images, batch_labels, opt_state, rng, config):\n",
    "    \"\"\"Single training step with data augmentation\"\"\"\n",
    "    # Apply data augmentation to the batch\n",
    "    if config.use_data_augmentation:\n",
    "        aug_images, rng = augment_batch(rng, batch_images)\n",
    "    else:\n",
    "        aug_images = batch_images\n",
    "    \n",
    "    # Define loss function for gradient computation\n",
    "    def loss_fn(p, bn):\n",
    "        loss, (updated_bn, updated_rng) = cross_entropy_loss(\n",
    "            p, bn, aug_images, batch_labels, True, rng, config\n",
    "        )\n",
    "        return loss, (updated_bn, updated_rng)\n",
    "    \n",
    "    # Compute loss and gradients\n",
    "    (loss, (updated_bn_stats, new_rng)), grads = value_and_grad(loss_fn, has_aux=True)(params, bn_stats)\n",
    "    \n",
    "    # Update parameters and optimizer state\n",
    "    optimizer = AdamWOptimizer(\n",
    "        learning_rate=config.current_lr,\n",
    "        weight_decay=config.weight_decay\n",
    "    )\n",
    "    updated_params, updated_opt_state = optimizer.update(params, grads, opt_state)\n",
    "    \n",
    "    return updated_params, updated_bn_stats, updated_opt_state, loss, new_rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3d0ec28-a7ab-4e0d-b3e7-2c108d5acdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main training function with improved model and regularization\"\"\"\n",
    "    print(\"\\n=== Improved CNN CIFAR-10 Classifier with Regularization ===\\n\")\n",
    "    \n",
    "    # --- MODEL CONFIGURATION ---\n",
    "    config = CNNConfig()\n",
    "    config.weight_decay = 1e-4  # L2 regularization factor\n",
    "    config.dropout_rate = 0.3   # Dropout rate\n",
    "    config.use_batch_norm = True\n",
    "    config.use_dropout = True\n",
    "    config.use_residual = True\n",
    "    config.use_global_pooling = True\n",
    "    config.use_data_augmentation = True\n",
    "    config.batch_norm_momentum = 0.9\n",
    "    \n",
    "    # --- TRAINING HYPERPARAMETERS ---\n",
    "    num_epochs = 50  # Train longer with early stopping\n",
    "    batch_size = 128\n",
    "    initial_learning_rate = 0.001\n",
    "    config.current_lr = initial_learning_rate  # For tracking during training\n",
    "    patience = 10  # Early stopping patience\n",
    "    checkpoint_path = 'best_cifar10_improved_model.pkl'\n",
    "    seed = 42\n",
    "    \n",
    "    # --- DEVICE SETUP ---\n",
    "    device = select_device(\"auto\")\n",
    "    \n",
    "    # --- DATA LOADING ---\n",
    "    print(\"\\nLoading CIFAR-10 dataset...\")\n",
    "    train_batches, valid_batches, test_batches = load_cifar10(\n",
    "        batch_size=batch_size, \n",
    "        seed=seed,\n",
    "        valid_ratio=0.1\n",
    "    )\n",
    "    \n",
    "    # --- MODEL INITIALIZATION ---\n",
    "    print(\"\\nInitializing model parameters...\")\n",
    "    rng = random.PRNGKey(seed)\n",
    "    rng, init_rng = random.split(rng)\n",
    "    params, bn_stats = initialize_improved_cnn_params(init_rng, config)\n",
    "    \n",
    "    # --- OPTIMIZER SETUP ---\n",
    "    print(\"Setting up AdamW optimizer...\")\n",
    "    optimizer = AdamWOptimizer(\n",
    "        learning_rate=initial_learning_rate,\n",
    "        weight_decay=config.weight_decay\n",
    "    )\n",
    "    opt_state = optimizer.init(params)\n",
    "    \n",
    "    # --- EARLY STOPPING ---\n",
    "    early_stopping = EarlyStopping(patience=patience)\n",
    "    \n",
    "    # --- METRICS TRACKING ---\n",
    "    train_losses, train_accuracies = [], []\n",
    "    valid_losses, valid_accuracies = [], []\n",
    "    best_valid_f1 = 0.0\n",
    "    \n",
    "    # --- TRAINING LOOP ---\n",
    "    print(\"\\nStarting training...\\n\")\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # Learning rate scheduling (cosine decay)\n",
    "        config.current_lr = cosine_decay_schedule(\n",
    "            initial_learning_rate, \n",
    "            epoch - 1,  # 0-indexed for the scheduler\n",
    "            num_epochs,\n",
    "            warmup_epochs=5\n",
    "        )\n",
    "        \n",
    "        print(f\"Epoch {epoch}/{num_epochs} - Learning Rate: {config.current_lr:.6f}\")\n",
    "        \n",
    "        # Training phase\n",
    "        epoch_losses = []\n",
    "        rng, train_rng = random.split(rng)\n",
    "        \n",
    "        for batch_idx, (batch_images, batch_labels) in enumerate(tqdm(train_batches, desc=\"Training\")):\n",
    "            # Convert to JAX arrays\n",
    "            batch_images = jnp.array(batch_images)\n",
    "            batch_labels = jnp.array(batch_labels)\n",
    "            \n",
    "            # Perform training step\n",
    "            rng, step_rng = random.split(rng)\n",
    "            params, bn_stats, opt_state, loss, rng = train_step(\n",
    "                params, bn_stats, batch_images, batch_labels, opt_state, step_rng, config\n",
    "            )\n",
    "            \n",
    "            epoch_losses.append(loss)\n",
    "            \n",
    "            # Print progress every 50 batches\n",
    "            if (batch_idx + 1) % 50 == 0:\n",
    "                print(f\"  Batch {batch_idx + 1}/{len(train_batches)}, Loss: {loss:.4f}\")\n",
    "        \n",
    "        # Calculate average training loss for the epoch\n",
    "        train_loss = jnp.mean(jnp.array(epoch_losses))\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # Evaluate on training set (using subset for efficiency)\n",
    "        print(\"Evaluating on training set...\")\n",
    "        train_eval_batches = train_batches[:len(train_batches)//10]  # Use 10% of training data for evaluation\n",
    "        rng, eval_rng = random.split(rng)\n",
    "        train_metrics = evaluate(params, bn_stats, train_eval_batches, eval_rng, config)\n",
    "        train_accuracy = train_metrics['accuracy']\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        print(\"Evaluating on validation set...\")\n",
    "        rng, valid_rng = random.split(rng)\n",
    "        valid_metrics = evaluate(params, bn_stats, valid_batches, valid_rng, config)\n",
    "        valid_losses.append(valid_metrics['loss'])\n",
    "        valid_accuracies.append(valid_metrics['accuracy'])\n",
    "        \n",
    "        # Save model if improved\n",
    "        if valid_metrics['f1'] > best_valid_f1:\n",
    "            best_valid_f1 = valid_metrics['f1']\n",
    "            save_model(params, bn_stats, checkpoint_path)\n",
    "            print(f\"✅ New best model saved (F1: {best_valid_f1:.4f})\")\n",
    "        \n",
    "        # Print epoch summary\n",
    "        print(f\"Epoch {epoch:02d} Summary:\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "        print(f\"  Valid Loss: {valid_metrics['loss']:.4f}, Valid Accuracy: {valid_metrics['accuracy']:.4f}\")\n",
    "        print(f\"  Valid Precision: {valid_metrics['precision']:.4f}, Valid Recall: {valid_metrics['recall']:.4f}, Valid F1: {valid_metrics['f1']:.4f}\")\n",
    "        \n",
    "        # Check for early stopping\n",
    "        if early_stopping(valid_metrics['loss']):\n",
    "            print(f\"Early stopping triggered after {epoch} epochs\")\n",
    "            break\n",
    "        \n",
    "        print()  # Add empty line between epochs\n",
    "    \n",
    "    # --- PLOT TRAINING CURVES ---\n",
    "    print(\"\\nPlotting training curves...\")\n",
    "    plot_training_curves(train_losses, valid_losses, train_accuracies, valid_accuracies)\n",
    "    \n",
    "    # --- FINAL EVALUATION ---\n",
    "    print(\"\\nLoading best model for final evaluation...\")\n",
    "    best_params, best_bn_stats = load_model(checkpoint_path)\n",
    "    \n",
    "    rng, final_rng = random.split(rng)\n",
    "    final_metrics = evaluate(best_params, best_bn_stats, test_batches, final_rng, config)\n",
    "    \n",
    "    print(\"\\n🏆 FINAL EVALUATION (Best Model):\")\n",
    "    print(f\"  Test Loss: {final_metrics['loss']:.4f}\")\n",
    "    print(f\"  Test Accuracy: {final_metrics['accuracy']:.4f}\")\n",
    "    print(f\"  Test Precision: {final_metrics['precision']:.4f}\")\n",
    "    print(f\"  Test Recall: {final_metrics['recall']:.4f}\")\n",
    "    print(f\"  Test F1: {final_metrics['f1']:.4f}\")\n",
    "    \n",
    "    print(\"\\nTraining completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2e42916-490f-441b-96e4-c36a6d3945c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Improved CNN CIFAR-10 Classifier with Regularization ===\n",
      "\n",
      "GPU detected, using GPU for training\n",
      "✅ Using device: cuda:0\n",
      "\n",
      "Loading CIFAR-10 dataset...\n",
      "Loading preprocessed CIFAR-10 data from cache...\n",
      "Created 352 training batches, 40 validation batches, and 79 test batches\n",
      "\n",
      "Initializing model parameters...\n",
      "Setting up AdamW optimizer...\n",
      "\n",
      "Starting training...\n",
      "\n",
      "Epoch 1/50 - Learning Rate: 0.000200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [01:21<04:15,  1.18it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 1.9237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [02:03<03:28,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 1.9139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:47<03:13,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 1.8251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:32<02:09,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 1.5903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [04:16<01:40,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 1.5646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [05:00<00:44,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 1.4121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:43<00:01,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 1.3999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [06:10<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "✅ Model saved at best_cifar10_improved_model.pkl\n",
      "✅ New best model saved (F1: 0.4032)\n",
      "Epoch 01 Summary:\n",
      "  Train Loss: 1.7215, Train Accuracy: 0.4330\n",
      "  Valid Loss: 1.6222, Valid Accuracy: 0.4363\n",
      "  Valid Precision: 0.4970, Valid Recall: 0.4291, Valid F1: 0.4032\n",
      "\n",
      "Epoch 2/50 - Learning Rate: 0.000400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:44<04:18,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 1.3208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:28<03:42,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 1.3378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:12<03:00,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 1.3045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [02:56<02:16,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 1.2723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [03:40<01:28,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 1.4532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [04:25<00:45,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 1.2474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:10<00:01,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 1.1812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [05:11<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "✅ Model saved at best_cifar10_improved_model.pkl\n",
      "✅ New best model saved (F1: 0.5135)\n",
      "Epoch 02 Summary:\n",
      "  Train Loss: 1.3279, Train Accuracy: 0.5254\n",
      "  Valid Loss: 1.3229, Valid Accuracy: 0.5281\n",
      "  Valid Precision: 0.5996, Valid Recall: 0.5193, Valid F1: 0.5135\n",
      "\n",
      "Epoch 3/50 - Learning Rate: 0.000600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:44<04:28,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 1.3100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:28<03:45,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 1.1067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:13<03:00,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 1.0744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [02:58<02:17,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 1.1404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [03:45<01:35,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 1.2821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [04:30<00:46,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 1.0305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:16<00:01,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 1.0391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [05:17<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "✅ Model saved at best_cifar10_improved_model.pkl\n",
      "✅ New best model saved (F1: 0.5529)\n",
      "Epoch 03 Summary:\n",
      "  Train Loss: 1.1524, Train Accuracy: 0.5844\n",
      "  Valid Loss: 1.1655, Valid Accuracy: 0.5814\n",
      "  Valid Precision: 0.6523, Valid Recall: 0.5716, Valid F1: 0.5529\n",
      "\n",
      "Epoch 4/50 - Learning Rate: 0.000800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:44<04:28,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 1.0757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:30<03:54,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 1.0286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:16<03:05,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 0.9571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:04<02:38,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 0.8873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [03:56<01:46,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 1.0920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [04:46<00:50,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 0.9857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:34<00:01,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 0.8382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [05:36<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "✅ Model saved at best_cifar10_improved_model.pkl\n",
      "✅ New best model saved (F1: 0.5809)\n",
      "Epoch 04 Summary:\n",
      "  Train Loss: 1.0200, Train Accuracy: 0.6121\n",
      "  Valid Loss: 1.1009, Valid Accuracy: 0.6086\n",
      "  Valid Precision: 0.6952, Valid Recall: 0.6004, Valid F1: 0.5809\n",
      "\n",
      "Epoch 5/50 - Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:47<04:43,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 0.9439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:35<04:04,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 0.9309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:23<03:10,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 0.7848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:11<02:29,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 0.8586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [03:59<01:37,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 0.9314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [04:47<00:50,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 0.8046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:35<00:01,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 0.8123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [05:37<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "✅ Model saved at best_cifar10_improved_model.pkl\n",
      "✅ New best model saved (F1: 0.6245)\n",
      "Epoch 05 Summary:\n",
      "  Train Loss: 0.9147, Train Accuracy: 0.6424\n",
      "  Valid Loss: 1.0070, Valid Accuracy: 0.6482\n",
      "  Valid Precision: 0.6918, Valid Recall: 0.6393, Valid F1: 0.6245\n",
      "\n",
      "Epoch 6/50 - Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:48<04:46,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 0.7499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:36<03:57,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 0.7284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:23<03:19,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 0.7392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:14<02:27,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 0.7882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [04:01<01:35,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 0.9093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [04:49<00:49,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 0.7130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:37<00:01,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 0.6330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [05:38<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "✅ Model saved at best_cifar10_improved_model.pkl\n",
      "✅ New best model saved (F1: 0.6530)\n",
      "Epoch 06 Summary:\n",
      "  Train Loss: 0.8088, Train Accuracy: 0.6621\n",
      "  Valid Loss: 0.9416, Valid Accuracy: 0.6674\n",
      "  Valid Precision: 0.7446, Valid Recall: 0.6578, Valid F1: 0.6530\n",
      "\n",
      "Epoch 7/50 - Learning Rate: 0.000999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:48<04:48,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 0.6201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:35<03:56,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 0.6556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:24<03:16,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 0.6729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:12<02:29,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 0.6870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [04:03<01:40,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 0.8327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [04:51<00:49,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 0.5880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:39<00:01,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 0.6758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [05:40<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "✅ Model saved at best_cifar10_improved_model.pkl\n",
      "✅ New best model saved (F1: 0.7199)\n",
      "Epoch 07 Summary:\n",
      "  Train Loss: 0.7311, Train Accuracy: 0.7348\n",
      "  Valid Loss: 0.7467, Valid Accuracy: 0.7334\n",
      "  Valid Precision: 0.7634, Valid Recall: 0.7245, Valid F1: 0.7199\n",
      "\n",
      "Epoch 8/50 - Learning Rate: 0.000995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:49<04:56,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 0.5782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:38<04:14,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 0.7400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:26<03:11,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 0.6245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:14<02:24,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 0.6646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [04:02<01:39,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 0.7316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [04:50<00:49,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 0.6311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:38<00:01,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 0.5503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [05:40<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "✅ Model saved at best_cifar10_improved_model.pkl\n",
      "✅ New best model saved (F1: 0.7252)\n",
      "Epoch 08 Summary:\n",
      "  Train Loss: 0.6695, Train Accuracy: 0.7373\n",
      "  Valid Loss: 0.7851, Valid Accuracy: 0.7338\n",
      "  Valid Precision: 0.7790, Valid Recall: 0.7248, Valid F1: 0.7252\n",
      "\n",
      "Epoch 9/50 - Learning Rate: 0.000989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:50<04:57,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 0.4650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:39<04:06,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 0.6009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:27<03:14,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 0.4661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:16<02:27,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 0.6128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [04:04<01:35,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 0.6090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [04:52<00:49,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 0.5631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:41<00:01,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 0.5830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [05:42<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "✅ Model saved at best_cifar10_improved_model.pkl\n",
      "✅ New best model saved (F1: 0.7761)\n",
      "Epoch 09 Summary:\n",
      "  Train Loss: 0.6237, Train Accuracy: 0.7817\n",
      "  Valid Loss: 0.6342, Valid Accuracy: 0.7879\n",
      "  Valid Precision: 0.8119, Valid Recall: 0.7821, Valid F1: 0.7761\n",
      "\n",
      "Epoch 10/50 - Learning Rate: 0.000981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:46<04:40,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 0.5093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:33<03:58,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 0.5292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:21<03:11,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 0.4277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:09<02:29,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 0.5609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [03:57<01:37,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 0.5428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [04:45<00:49,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 0.5856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:32<00:01,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 0.4783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [05:33<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "✅ Model saved at best_cifar10_improved_model.pkl\n",
      "✅ New best model saved (F1: 0.7881)\n",
      "Epoch 10 Summary:\n",
      "  Train Loss: 0.5817, Train Accuracy: 0.8042\n",
      "  Valid Loss: 0.6100, Valid Accuracy: 0.7994\n",
      "  Valid Precision: 0.8102, Valid Recall: 0.7904, Valid F1: 0.7881\n",
      "\n",
      "Epoch 11/50 - Learning Rate: 0.000970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:47<04:46,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 0.4067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:34<03:57,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 0.4624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:22<03:14,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 0.4090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:10<02:25,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 0.5548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [03:58<01:38,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 0.5904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [04:46<00:48,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 0.5868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:34<00:01,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 0.4923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [05:35<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "Epoch 11 Summary:\n",
      "  Train Loss: 0.5434, Train Accuracy: 0.8047\n",
      "  Valid Loss: 0.6297, Valid Accuracy: 0.7904\n",
      "  Valid Precision: 0.7991, Valid Recall: 0.7843, Valid F1: 0.7778\n",
      "\n",
      "Epoch 12/50 - Learning Rate: 0.000957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:48<05:01,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 0.3448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:36<04:01,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 0.4410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:25<03:13,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 0.3945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:12<02:22,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 0.5221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [04:00<01:41,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 0.4727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [04:48<00:48,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 0.4266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:34<00:01,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 0.5290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [05:36<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "Epoch 12 Summary:\n",
      "  Train Loss: 0.5067, Train Accuracy: 0.7783\n",
      "  Valid Loss: 0.6864, Valid Accuracy: 0.7625\n",
      "  Valid Precision: 0.7929, Valid Recall: 0.7538, Valid F1: 0.7462\n",
      "\n",
      "Epoch 13/50 - Learning Rate: 0.000941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:47<04:45,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 0.3807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:38<04:27,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 0.4391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:26<03:15,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 0.4111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:15<02:43,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 0.4798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [04:07<01:36,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 0.5092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [04:55<00:50,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 0.5027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:43<00:01,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 0.4577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [05:45<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "Epoch 13 Summary:\n",
      "  Train Loss: 0.4842, Train Accuracy: 0.7987\n",
      "  Valid Loss: 0.6288, Valid Accuracy: 0.7908\n",
      "  Valid Precision: 0.8097, Valid Recall: 0.7834, Valid F1: 0.7776\n",
      "\n",
      "Epoch 14/50 - Learning Rate: 0.000924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:47<04:40,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 0.3037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:34<04:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 0.4511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:23<03:15,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 0.3789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:11<02:22,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 0.4105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [04:01<01:39,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 0.4686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [04:49<00:52,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 0.4194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:36<00:01,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 0.3998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [05:38<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "Epoch 14 Summary:\n",
      "  Train Loss: 0.4526, Train Accuracy: 0.8116\n",
      "  Valid Loss: 0.6230, Valid Accuracy: 0.7906\n",
      "  Valid Precision: 0.8086, Valid Recall: 0.7832, Valid F1: 0.7810\n",
      "\n",
      "Epoch 15/50 - Learning Rate: 0.000905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:48<04:45,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 0.3728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:36<04:10,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 0.3980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:25<03:17,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 0.3618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:14<02:23,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 0.4892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [04:02<01:39,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 0.4183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [04:49<00:49,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 0.4022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:37<00:01,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 0.3635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [05:38<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "✅ Model saved at best_cifar10_improved_model.pkl\n",
      "✅ New best model saved (F1: 0.8364)\n",
      "Epoch 15 Summary:\n",
      "  Train Loss: 0.4346, Train Accuracy: 0.8654\n",
      "  Valid Loss: 0.4412, Valid Accuracy: 0.8480\n",
      "  Valid Precision: 0.8449, Valid Recall: 0.8416, Valid F1: 0.8364\n",
      "\n",
      "Epoch 16/50 - Learning Rate: 0.000883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:47<04:50,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 0.3022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:36<04:19,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 0.4916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:25<03:11,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 0.3619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:13<02:24,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 0.3985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [04:00<01:36,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 0.4016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [04:48<00:49,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 0.4529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:36<00:01,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 0.3494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [05:37<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "✅ Model saved at best_cifar10_improved_model.pkl\n",
      "✅ New best model saved (F1: 0.8445)\n",
      "Epoch 16 Summary:\n",
      "  Train Loss: 0.4125, Train Accuracy: 0.8717\n",
      "  Valid Loss: 0.4186, Valid Accuracy: 0.8578\n",
      "  Valid Precision: 0.8529, Valid Recall: 0.8513, Valid F1: 0.8445\n",
      "\n",
      "Epoch 17/50 - Learning Rate: 0.000860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:49<05:20,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 0.2351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:42<04:05,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 0.3689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:30<03:10,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 0.2915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:17<02:23,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 0.4102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [04:04<01:37,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 0.3036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [04:51<00:48,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 0.3354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:39<00:01,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 0.3050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [05:40<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "Epoch 17 Summary:\n",
      "  Train Loss: 0.3863, Train Accuracy: 0.8449\n",
      "  Valid Loss: 0.4950, Valid Accuracy: 0.8326\n",
      "  Valid Precision: 0.8381, Valid Recall: 0.8266, Valid F1: 0.8195\n",
      "\n",
      "Epoch 18/50 - Learning Rate: 0.000835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:47<04:46,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 0.1854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:35<04:01,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 0.3230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:22<03:18,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 0.2780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:14<02:42,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 0.3727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [04:07<01:37,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 0.3439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [04:55<00:50,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 0.3488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:42<00:01,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 0.2220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [05:43<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "✅ Model saved at best_cifar10_improved_model.pkl\n",
      "✅ New best model saved (F1: 0.8508)\n",
      "Epoch 18 Summary:\n",
      "  Train Loss: 0.3669, Train Accuracy: 0.8743\n",
      "  Valid Loss: 0.4172, Valid Accuracy: 0.8641\n",
      "  Valid Precision: 0.8580, Valid Recall: 0.8551, Valid F1: 0.8508\n",
      "\n",
      "Epoch 19/50 - Learning Rate: 0.000808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:47<04:41,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 0.2546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:34<04:02,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 0.3671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:21<03:12,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 0.2508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:09<02:21,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 0.4016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [03:56<01:34,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 0.3058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [04:44<00:49,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 0.3519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:31<00:01,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 0.2675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [05:33<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "✅ Model saved at best_cifar10_improved_model.pkl\n",
      "✅ New best model saved (F1: 0.8610)\n",
      "Epoch 19 Summary:\n",
      "  Train Loss: 0.3493, Train Accuracy: 0.8913\n",
      "  Valid Loss: 0.3868, Valid Accuracy: 0.8738\n",
      "  Valid Precision: 0.8698, Valid Recall: 0.8658, Valid F1: 0.8610\n",
      "\n",
      "Epoch 20/50 - Learning Rate: 0.000780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:47<04:49,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 0.2445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:35<04:01,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 0.3448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:22<03:10,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 0.2661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:10<02:27,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 0.3926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [03:57<01:36,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 0.2832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [04:46<00:58,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 0.2776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:34<00:01,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 0.2837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [05:35<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "Epoch 20 Summary:\n",
      "  Train Loss: 0.3315, Train Accuracy: 0.8683\n",
      "  Valid Loss: 0.4691, Valid Accuracy: 0.8438\n",
      "  Valid Precision: 0.8487, Valid Recall: 0.8368, Valid F1: 0.8304\n",
      "\n",
      "Epoch 21/50 - Learning Rate: 0.000750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:46<04:40,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 0.2504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:33<03:54,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 0.3315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:21<03:13,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 0.2860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:14<02:51,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 0.4623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [04:03<01:38,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 0.2695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [04:51<00:49,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 0.3446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:39<00:01,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 0.2602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [05:40<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "Epoch 21 Summary:\n",
      "  Train Loss: 0.3149, Train Accuracy: 0.8741\n",
      "  Valid Loss: 0.4793, Valid Accuracy: 0.8447\n",
      "  Valid Precision: 0.8530, Valid Recall: 0.8395, Valid F1: 0.8357\n",
      "\n",
      "Epoch 22/50 - Learning Rate: 0.000719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:47<04:45,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 0.1980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:35<04:03,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 0.3381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:25<03:36,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 0.2581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:14<02:22,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 0.3824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [04:02<01:39,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 0.2327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [04:50<00:49,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 0.2532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:37<00:01,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 0.2730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [05:39<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "Epoch 22 Summary:\n",
      "  Train Loss: 0.2967, Train Accuracy: 0.8754\n",
      "  Valid Loss: 0.4949, Valid Accuracy: 0.8369\n",
      "  Valid Precision: 0.8435, Valid Recall: 0.8301, Valid F1: 0.8251\n",
      "\n",
      "Epoch 23/50 - Learning Rate: 0.000687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:47<04:45,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 0.2576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:39<04:25,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 0.2918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:29<03:10,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 0.1836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:16<02:24,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 0.2577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [04:04<01:40,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 0.1688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [04:51<00:49,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 0.2492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:38<00:01,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 0.1978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [05:40<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "Epoch 23 Summary:\n",
      "  Train Loss: 0.2844, Train Accuracy: 0.8850\n",
      "  Valid Loss: 0.4491, Valid Accuracy: 0.8570\n",
      "  Valid Precision: 0.8619, Valid Recall: 0.8512, Valid F1: 0.8451\n",
      "\n",
      "Epoch 24/50 - Learning Rate: 0.000655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:46<04:39,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 0.1458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:34<04:03,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 0.3385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:21<03:12,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 0.2067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:09<02:23,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 0.2435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [03:56<01:36,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 0.2624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [04:44<00:48,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 0.1699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:32<00:01,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 0.1801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [05:33<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "Epoch 24 Summary:\n",
      "  Train Loss: 0.2695, Train Accuracy: 0.8989\n",
      "  Valid Loss: 0.4250, Valid Accuracy: 0.8652\n",
      "  Valid Precision: 0.8656, Valid Recall: 0.8574, Valid F1: 0.8524\n",
      "\n",
      "Epoch 25/50 - Learning Rate: 0.000621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:48<04:47,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 0.1734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:35<03:57,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 0.2496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:23<03:16,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 0.1805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:10<02:24,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 0.3347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [03:58<01:36,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 0.2622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [04:45<00:49,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 0.3122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:32<00:01,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 0.1796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [05:34<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "Epoch 25 Summary:\n",
      "  Train Loss: 0.2520, Train Accuracy: 0.9069\n",
      "  Valid Loss: 0.3976, Valid Accuracy: 0.8729\n",
      "  Valid Precision: 0.8731, Valid Recall: 0.8661, Valid F1: 0.8608\n",
      "\n",
      "Epoch 26/50 - Learning Rate: 0.000587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:47<04:46,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 0.1514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:35<04:01,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 0.2861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:22<03:11,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 0.1641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:10<02:26,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 0.2303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [03:58<01:37,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 0.1499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [04:46<00:49,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 0.2720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:37<00:02,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 0.1782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [05:39<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "Epoch 26 Summary:\n",
      "  Train Loss: 0.2419, Train Accuracy: 0.9150\n",
      "  Valid Loss: 0.4006, Valid Accuracy: 0.8695\n",
      "  Valid Precision: 0.8709, Valid Recall: 0.8633, Valid F1: 0.8590\n",
      "\n",
      "Epoch 27/50 - Learning Rate: 0.000552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:49<04:43,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 0.1022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:37<03:56,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 0.2928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:24<03:15,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 0.2108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:13<02:25,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 0.2541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [04:04<01:51,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 0.1810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [04:56<00:48,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 0.2274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:43<00:01,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 0.1418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [05:45<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "✅ Model saved at best_cifar10_improved_model.pkl\n",
      "✅ New best model saved (F1: 0.8763)\n",
      "Epoch 27 Summary:\n",
      "  Train Loss: 0.2272, Train Accuracy: 0.9337\n",
      "  Valid Loss: 0.3329, Valid Accuracy: 0.8906\n",
      "  Valid Precision: 0.8810, Valid Recall: 0.8821, Valid F1: 0.8763\n",
      "\n",
      "Epoch 28/50 - Learning Rate: 0.000517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:47<04:47,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 0.1922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:34<03:58,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 0.1590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:22<03:14,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 0.1902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:10<02:26,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 0.2642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [03:59<01:39,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 0.1206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [04:47<00:51,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 0.2471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:35<00:01,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 0.1199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [05:37<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "Epoch 28 Summary:\n",
      "  Train Loss: 0.2154, Train Accuracy: 0.9328\n",
      "  Valid Loss: 0.3403, Valid Accuracy: 0.8906\n",
      "  Valid Precision: 0.8804, Valid Recall: 0.8804, Valid F1: 0.8744\n",
      "\n",
      "Epoch 29/50 - Learning Rate: 0.000483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:47<04:45,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 0.1467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:35<03:58,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 0.1544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:24<03:33,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 0.2091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:12<02:25,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 0.2105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [04:02<01:41,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 0.1835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [04:52<00:50,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 0.1968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:42<00:01,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 0.2147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [05:43<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "Epoch 29 Summary:\n",
      "  Train Loss: 0.2037, Train Accuracy: 0.9174\n",
      "  Valid Loss: 0.3759, Valid Accuracy: 0.8797\n",
      "  Valid Precision: 0.8751, Valid Recall: 0.8710, Valid F1: 0.8662\n",
      "\n",
      "Epoch 30/50 - Learning Rate: 0.000448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:49<04:55,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 0.1520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:38<04:07,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 0.1803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:27<03:17,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 0.1984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:17<02:33,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 0.2501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [04:07<01:38,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 0.1574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [04:57<00:51,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 0.2645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:47<00:02,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 0.1488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [05:49<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "Epoch 30 Summary:\n",
      "  Train Loss: 0.1894, Train Accuracy: 0.9290\n",
      "  Valid Loss: 0.3872, Valid Accuracy: 0.8791\n",
      "  Valid Precision: 0.8752, Valid Recall: 0.8721, Valid F1: 0.8653\n",
      "\n",
      "Epoch 31/50 - Learning Rate: 0.000413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:49<04:50,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 0.2123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:37<04:05,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 0.1858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:25<03:09,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 0.1669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:13<02:28,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 0.2076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [04:02<01:47,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 0.1549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [04:50<00:50,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 0.1906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:38<00:01,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 0.1128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [05:39<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "Epoch 31 Summary:\n",
      "  Train Loss: 0.1839, Train Accuracy: 0.9366\n",
      "  Valid Loss: 0.3476, Valid Accuracy: 0.8879\n",
      "  Valid Precision: 0.8800, Valid Recall: 0.8796, Valid F1: 0.8735\n",
      "\n",
      "Epoch 32/50 - Learning Rate: 0.000379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:47<04:50,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 0.1159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:35<04:05,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 0.1928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:23<03:10,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 0.1731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:11<02:24,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 0.3092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [03:58<01:37,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 0.1453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [04:46<00:50,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 0.1887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:34<00:01,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 0.1067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [05:36<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "Epoch 32 Summary:\n",
      "  Train Loss: 0.1708, Train Accuracy: 0.9355\n",
      "  Valid Loss: 0.3944, Valid Accuracy: 0.8803\n",
      "  Valid Precision: 0.8782, Valid Recall: 0.8720, Valid F1: 0.8671\n",
      "\n",
      "Epoch 33/50 - Learning Rate: 0.000345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:46<04:39,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 0.1073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:33<03:56,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 0.1533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:21<03:13,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 0.0890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:09<02:22,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 0.2060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [03:56<01:36,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 0.1896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [04:43<00:51,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 0.1375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:35<00:02,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 0.1110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [05:37<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "✅ Model saved at best_cifar10_improved_model.pkl\n",
      "✅ New best model saved (F1: 0.8771)\n",
      "Epoch 33 Summary:\n",
      "  Train Loss: 0.1636, Train Accuracy: 0.9453\n",
      "  Valid Loss: 0.3618, Valid Accuracy: 0.8906\n",
      "  Valid Precision: 0.8842, Valid Recall: 0.8832, Valid F1: 0.8771\n",
      "\n",
      "Epoch 34/50 - Learning Rate: 0.000313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:48<05:15,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 0.0803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:38<04:04,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 0.1333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:27<03:32,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 0.1098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:18<02:23,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 0.2057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [04:05<01:35,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 0.1141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [04:52<00:49,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 0.2015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:41<00:01,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 0.0904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [05:42<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "✅ Model saved at best_cifar10_improved_model.pkl\n",
      "✅ New best model saved (F1: 0.8814)\n",
      "Epoch 34 Summary:\n",
      "  Train Loss: 0.1577, Train Accuracy: 0.9484\n",
      "  Valid Loss: 0.3353, Valid Accuracy: 0.8949\n",
      "  Valid Precision: 0.8879, Valid Recall: 0.8868, Valid F1: 0.8814\n",
      "\n",
      "Epoch 35/50 - Learning Rate: 0.000281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:47<04:41,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 0.1222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:34<03:56,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 0.1281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:21<03:10,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 0.2321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:10<02:40,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 0.1951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [04:00<01:37,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 0.1552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [04:47<00:48,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 0.1888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:34<00:01,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 0.0999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [05:36<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "✅ Model saved at best_cifar10_improved_model.pkl\n",
      "✅ New best model saved (F1: 0.8885)\n",
      "Epoch 35 Summary:\n",
      "  Train Loss: 0.1440, Train Accuracy: 0.9627\n",
      "  Valid Loss: 0.3159, Valid Accuracy: 0.9012\n",
      "  Valid Precision: 0.8948, Valid Recall: 0.8919, Valid F1: 0.8885\n",
      "\n",
      "Epoch 36/50 - Learning Rate: 0.000250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:49<04:46,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 0.1023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:37<04:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 0.1176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:23<03:09,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 0.1492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:10<02:21,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 0.2571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [03:58<01:37,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 0.0912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [04:46<00:49,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 0.1365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:33<00:01,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 0.1025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [05:35<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "✅ Model saved at best_cifar10_improved_model.pkl\n",
      "✅ New best model saved (F1: 0.8887)\n",
      "Epoch 36 Summary:\n",
      "  Train Loss: 0.1357, Train Accuracy: 0.9609\n",
      "  Valid Loss: 0.3200, Valid Accuracy: 0.9020\n",
      "  Valid Precision: 0.8942, Valid Recall: 0.8933, Valid F1: 0.8887\n",
      "\n",
      "Epoch 37/50 - Learning Rate: 0.000220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:46<04:39,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 0.0982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:37<04:16,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 0.0665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:29<03:16,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 0.0712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:17<02:24,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 0.1608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [04:05<01:37,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 0.1064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [04:53<00:50,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 0.1091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:40<00:02,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 0.0996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [05:42<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "✅ Model saved at best_cifar10_improved_model.pkl\n",
      "✅ New best model saved (F1: 0.8917)\n",
      "Epoch 37 Summary:\n",
      "  Train Loss: 0.1314, Train Accuracy: 0.9667\n",
      "  Valid Loss: 0.3123, Valid Accuracy: 0.9047\n",
      "  Valid Precision: 0.8960, Valid Recall: 0.8964, Valid F1: 0.8917\n",
      "\n",
      "Epoch 38/50 - Learning Rate: 0.000192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [01:02<06:21,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 0.0547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:52<03:55,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 0.1432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:39<03:10,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 0.0631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:27<02:29,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 0.1705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [04:19<01:53,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 0.0699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [05:12<00:49,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 0.1514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:59<00:01,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 0.0810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [06:01<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "Epoch 38 Summary:\n",
      "  Train Loss: 0.1220, Train Accuracy: 0.9587\n",
      "  Valid Loss: 0.3411, Valid Accuracy: 0.9035\n",
      "  Valid Precision: 0.8972, Valid Recall: 0.8959, Valid F1: 0.8911\n",
      "\n",
      "Epoch 39/50 - Learning Rate: 0.000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:47<04:45,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 0.1174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:35<03:58,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 0.1787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:23<03:14,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 0.1077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:10<02:23,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 0.0819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [03:58<01:36,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 0.1612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [04:45<00:49,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 0.1837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:33<00:01,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 0.0769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [05:35<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "Epoch 39 Summary:\n",
      "  Train Loss: 0.1188, Train Accuracy: 0.9683\n",
      "  Valid Loss: 0.3196, Valid Accuracy: 0.9033\n",
      "  Valid Precision: 0.8964, Valid Recall: 0.8939, Valid F1: 0.8906\n",
      "\n",
      "Epoch 40/50 - Learning Rate: 0.000140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:48<04:53,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 0.1671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:36<04:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 0.0768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:24<03:14,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 0.0984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:13<02:30,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 0.1353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [04:02<01:37,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 0.1160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [04:50<00:49,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 0.0678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:39<00:01,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 0.0502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [05:40<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "Epoch 40 Summary:\n",
      "  Train Loss: 0.1114, Train Accuracy: 0.9661\n",
      "  Valid Loss: 0.3250, Valid Accuracy: 0.9035\n",
      "  Valid Precision: 0.8964, Valid Recall: 0.8937, Valid F1: 0.8899\n",
      "\n",
      "Epoch 41/50 - Learning Rate: 0.000117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:49<04:50,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 0.1232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:38<04:08,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 0.0994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:25<03:12,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 0.0342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:14<02:25,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 0.1929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [04:02<01:36,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 0.0884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [04:50<00:50,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 0.1258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:39<00:01,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 0.0380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [05:40<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "Epoch 41 Summary:\n",
      "  Train Loss: 0.1074, Train Accuracy: 0.9708\n",
      "  Valid Loss: 0.3212, Valid Accuracy: 0.9029\n",
      "  Valid Precision: 0.8957, Valid Recall: 0.8933, Valid F1: 0.8892\n",
      "\n",
      "Epoch 42/50 - Learning Rate: 0.000095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:49<04:59,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 0.1322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:40<04:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 0.0825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:31<03:31,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 0.0683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:20<02:26,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 0.1261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [04:09<01:40,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 0.0578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [04:58<00:50,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 0.0959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:47<00:01,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 0.0553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [05:48<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "✅ Model saved at best_cifar10_improved_model.pkl\n",
      "✅ New best model saved (F1: 0.8918)\n",
      "Epoch 42 Summary:\n",
      "  Train Loss: 0.0988, Train Accuracy: 0.9712\n",
      "  Valid Loss: 0.3192, Valid Accuracy: 0.9055\n",
      "  Valid Precision: 0.8982, Valid Recall: 0.8954, Valid F1: 0.8918\n",
      "\n",
      "Epoch 43/50 - Learning Rate: 0.000076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:48<05:03,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 0.0880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:37<04:10,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 0.0945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:28<03:22,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 0.0421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:20<02:46,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 0.0509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [04:13<01:39,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 0.0609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [05:03<00:51,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 0.1389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:52<00:02,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 0.0655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [05:54<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "✅ Model saved at best_cifar10_improved_model.pkl\n",
      "✅ New best model saved (F1: 0.8959)\n",
      "Epoch 43 Summary:\n",
      "  Train Loss: 0.0979, Train Accuracy: 0.9752\n",
      "  Valid Loss: 0.3091, Valid Accuracy: 0.9088\n",
      "  Valid Precision: 0.9018, Valid Recall: 0.8994, Valid F1: 0.8959\n",
      "\n",
      "Epoch 44/50 - Learning Rate: 0.000059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:49<04:55,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 0.0687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:39<04:16,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 0.0748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:27<03:15,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 0.1298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:17<02:31,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 0.0687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [04:06<01:38,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 0.0609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [04:55<00:58,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 0.1080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:45<00:01,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 0.0600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [05:47<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "Epoch 44 Summary:\n",
      "  Train Loss: 0.0928, Train Accuracy: 0.9768\n",
      "  Valid Loss: 0.3089, Valid Accuracy: 0.9092\n",
      "  Valid Precision: 0.9011, Valid Recall: 0.8992, Valid F1: 0.8959\n",
      "\n",
      "Epoch 45/50 - Learning Rate: 0.000043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:49<04:56,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 0.0616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:38<04:02,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 0.1041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:29<03:20,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 0.0663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:18<02:25,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 0.1511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [04:06<01:37,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 0.0792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [04:56<00:53,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 0.0726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:45<00:01,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 0.1271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [05:47<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "✅ Model saved at best_cifar10_improved_model.pkl\n",
      "✅ New best model saved (F1: 0.8999)\n",
      "Epoch 45 Summary:\n",
      "  Train Loss: 0.0898, Train Accuracy: 0.9801\n",
      "  Valid Loss: 0.2994, Valid Accuracy: 0.9131\n",
      "  Valid Precision: 0.9045, Valid Recall: 0.9033, Valid F1: 0.8999\n",
      "\n",
      "Epoch 46/50 - Learning Rate: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:51<05:24,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 0.0932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:41<04:14,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 0.1282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:34<03:55,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 0.0399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:27<02:43,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 0.1177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [04:19<01:45,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 0.0879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [05:10<00:51,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 0.1321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [06:02<00:02,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 0.0770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [06:03<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "Epoch 46 Summary:\n",
      "  Train Loss: 0.0859, Train Accuracy: 0.9797\n",
      "  Valid Loss: 0.3026, Valid Accuracy: 0.9131\n",
      "  Valid Precision: 0.9044, Valid Recall: 0.9029, Valid F1: 0.8996\n",
      "\n",
      "Epoch 47/50 - Learning Rate: 0.000019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:51<05:16,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 0.0973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:43<04:21,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 0.0483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:35<03:20,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 0.0542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:28<02:38,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 0.0984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [04:19<01:44,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 0.1170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [05:10<00:54,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 0.0855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [06:02<00:02,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 0.0723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [06:04<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "Epoch 47 Summary:\n",
      "  Train Loss: 0.0873, Train Accuracy: 0.9810\n",
      "  Valid Loss: 0.2993, Valid Accuracy: 0.9117\n",
      "  Valid Precision: 0.9030, Valid Recall: 0.9016, Valid F1: 0.8983\n",
      "\n",
      "Epoch 48/50 - Learning Rate: 0.000011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:53<05:08,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 0.0665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:43<04:17,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 0.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:34<03:27,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 0.0879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:24<02:27,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 0.1010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [04:14<01:41,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 0.0658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [05:04<00:52,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 0.0692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:56<00:01,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 0.0662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [05:57<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "Epoch 48 Summary:\n",
      "  Train Loss: 0.0868, Train Accuracy: 0.9810\n",
      "  Valid Loss: 0.2992, Valid Accuracy: 0.9119\n",
      "  Valid Precision: 0.9033, Valid Recall: 0.9021, Valid F1: 0.8987\n",
      "\n",
      "Epoch 49/50 - Learning Rate: 0.000005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:50<05:01,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 0.0678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:40<04:18,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 0.0964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:30<03:29,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 0.0552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:20<02:28,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 0.1205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [04:10<01:41,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 0.0540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [05:01<00:52,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 0.0775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:53<00:02,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 0.0363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [05:54<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "Epoch 49 Summary:\n",
      "  Train Loss: 0.0860, Train Accuracy: 0.9821\n",
      "  Valid Loss: 0.2983, Valid Accuracy: 0.9123\n",
      "  Valid Precision: 0.9033, Valid Recall: 0.9025, Valid F1: 0.8992\n",
      "\n",
      "Epoch 50/50 - Learning Rate: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 50/352 [00:51<05:03,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 50/352, Loss: 0.1291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 100/352 [01:42<04:11,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 100/352, Loss: 0.1043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 150/352 [02:33<03:26,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 150/352, Loss: 0.0931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 200/352 [03:23<02:40,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 200/352, Loss: 0.1112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|███████   | 250/352 [04:14<01:46,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 250/352, Loss: 0.0407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 300/352 [05:04<00:52,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 300/352, Loss: 0.0840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  99%|█████████▉| 350/352 [05:55<00:01,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 350/352, Loss: 0.1006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 352/352 [05:56<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on training set...\n",
      "Evaluating on validation set...\n",
      "Epoch 50 Summary:\n",
      "  Train Loss: 0.0844, Train Accuracy: 0.9812\n",
      "  Valid Loss: 0.2998, Valid Accuracy: 0.9111\n",
      "  Valid Precision: 0.9023, Valid Recall: 0.9016, Valid F1: 0.8980\n",
      "\n",
      "\n",
      "Plotting training curves...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading best model for final evaluation...\n",
      "✅ Model loaded from best_cifar10_improved_model.pkl\n",
      "\n",
      "🏆 FINAL EVALUATION (Best Model):\n",
      "  Test Loss: 0.3370\n",
      "  Test Accuracy: 0.9026\n",
      "  Test Precision: 0.8985\n",
      "  Test Recall: 0.8976\n",
      "  Test F1: 0.8941\n",
      "\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae1dc86-6282-4fd8-bf22-a5bdd0103341",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707c4dce-c250-4983-8d99-59b043e8b2d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
